{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da9edbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -Uqq fastbook\n",
    "import fastbook\n",
    "fastbook.setup_book()\n",
    "from fastbook import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8b9a102",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6587fa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rc('image', cmap=\"Greys_r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73d4a9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import *\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f676d226",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3a0236a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [Path('train/3'),Path('train/7')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Path('/storage/data/mnist_sample/')\n",
    "Path.BASE_PATH = path\n",
    "(path/'train').ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2b834187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((#2) [Path('train/3'),Path('train/7')],\n",
       " (#2) [Path('valid/3'),Path('valid/7')])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = path/'train'\n",
    "valid = path/'valid'\n",
    "train.ls(), valid.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ff1beee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training paths\n",
    "threes_train_f = train/'3'\n",
    "seven_train_f = train/'7'\n",
    "\n",
    "# validation paths\n",
    "threes_valid_f = valid/'3'\n",
    "seven_valid_f = valid/'7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3a21facb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEQAAABECAYAAAA4E5OyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAJDklEQVR4nO2bS28bVRuAn/HYHnvGjj1jJ83ViYmSlKZNoLQhhi4KZdFVF/wCxJa/wQ9AYgF/AQkJFkViUySuBUEVJxVN6jS0Edi5NPGt44nH9ni+BfJ8jXOhqe3Ax+dnF8/Yev34nPe85z0TwbZtuvwX198dwD+NrpAmukKa6AppoiukCfdxFwVB+NcuQbZtC4e93h0hTXSFNNEV0kRXSBNdIU10hTRx7LLbCURRRJIkZFkmGAwSCoVQVZVarUalUmF9fZ3NzU0CgQCKouByuXC5XBQKBcrlMh6PB5fLRblcxrKstsd36kJ6enoYGBjgpZdeYnZ2lsuXL/Piiy9iGAa6rvPxxx/z0UcfMT09zfnz51EUBUmS+P7771lZWaGvr49AIMCDBw/I5/Ntj+/UhQiCgCiKaJrGuXPnGBwcpKenB5/PhyzLvPLKK7z99ttMTk4Sj8dRFAWv14vX62VycpJQKIQkSZw9e5Z8Ps+vv/5KLpdD13VqtVrr8R3XD+lEpappGkNDQ7zzzju8++67SJKEz+fDtm1s26ZWq2FZljNVBOHPgrJer1Ov152/a7Ua1WqVDz74gG+++YZkMnmiEXNUpXrqI0RRFEZHR9E0DVEU931pQRDweDx4PB7ntad5+sdzu9243W7i8TgbGxusrq62ZQqdupChoSEuX77MCy+8sE9Gg8NEHHZNFEUEQWBubg5N01hYWCCdTrcc36kvu7qus729TaFQcKbJ87YxBUEgHA4Ti8UYHR0lEongdrf2G5+6kD/++IOvvvqKVCqFZVnPLQP+FNLX18fU1BSzs7NcvHiRQCDQUnynPmWq1SrFYpHt7W22traQZRlFUQ7c5/F4cLvdVKtVLMvC6/XidrudvNOgkXzD4TDRaLTlEXLqQsrlMtlsllQqxddff004HEZV1X33CIJAf38/qqqytbVFNptlbGwMTdOQZRmv17vvXpfLxeDgICMjI8iy3FJ8py6ksbQ+fPiQn376CVmW8fv9B+6bmpoiHo9TLBYxDINYLIbb7d43Op7+zHw+Ty6Xo1KptBTfqQtp1BOLi4ssLS0duarMz88zPT1NJBIhHA5z6dIlJEk6IKTxeZlMhocPH1Iul1uK79SEBAIBotEoLpfr0Hnu9/vx+XyMjIygaRoTExOMjo6iqiqyLKOq6qHLdLVaxTRNBEFAluVDR9BJODUh0WiURCLhVKbNNDZ5V65cYXJyEr/f7yTW477k3t4ehUIBURQJBoP/O0k1Ho/z5ptvEgwG0TTtwHWfz4ckSQwMDCDLsrOiHDWl6vU6lmVx9+5dFhcXSSaTrK2tYRhGS3GempCJiQlu3LiBoigtrwQAlmVRqVT45JNP+PTTT8nn8y0nVOigELfbjd/vZ2xsjPn5ea5evYrf7295SFuWRb1eZ2VlhQcPHpBKpSiVSm3rjXRMiNfrRdM0Xn/9dd577z2i0Sh+v//Yvcqz0BgZn332GV9++SUrKyuUSqU2Rd3B0t22ber1Orqus7Gxga7rCILQspDGKnX27FleffXVA0Vdq3RUSK1Wo1gskkqlKBQKhy6bJ0UURTweD1NTUyQSCfr6+toU8Z90bMp4PB5UVaW/v5+ZmRmi0eiJ3v/0Tti2bWfF0XUdXddJJpPcvXuXx48ftzXujuaQSCTCwMAAY2Nj9PT0nOj9tm07CdS2baf1mMvlyGQyLCwssLCwQC6Xa2vcHRNSKpVYW1tDVVVu3rzJ4OAgo6OjhMPhfXWIrusUi0VM08Q0TcrlMnt7e5imSaVSIRQK4fP5mJ6eRlVVIpEIfr+fN954g97eXnZ2dtoqpWNCyuUymUyGn3/+2elbjI+PMz09zYULF5z70uk0Kysr5HI5CoUCu7u75HI5R1AsFqO3t5ehoSFUVXXqmJmZGTRN49atWywvL7ct7o4XZsVikWQyiaIo3L9/nzt37uxLhIVCgVwuh2EY7O3tUSqV9lWbFy5c4NKlSwQCASch27bN48ePuXfvXtuPIjoupFQqPVed4PF4kCSJUCjE+Pj4gRbB7u4ujx494smTJ+0KFfgbtv9/RSQSIRKJ8NprrzE1NcX169cZHh5GkiQn0dZqNVKpFMvLy/9+IeFwmPHxcRKJBFeuXGF4eJhgMOhcb2zqNjc3216lQhuFNOqOSqVCsVh85m5648Sup6eHUCjEjRs3eOutt4jFYkQiESRJ2nd/tVrFMAx2dnbY2NjANM12fQWgjUIaexfDMDAMw+lkHUVDls/nIxQKMTw8TH9/P4lEgosXL+L1evF4PAfeV6vV2Nvb48mTJ22fLtBGIbOzs7z//vsUi0UWFxedo8ZmDMMgn8+TzWZJp9Ncu3aN69evEwgECAaDnDlzBkmSEEVx3/ssy8KyLG7fvs13333H0tJSu0LfR1uECILAyMgIc3NzmKZJb28vtVrt0MPn3d1d0uk0mUwGRVFIJBLMz887R5iH0Uim1WqVZDLJrVu32NraakfoB2hZSDAY5Ny5c0xMTCCKIoqicP78+SNzSGPkVCoVTNN08sRR3fTG+U02myWbzbK6uoppmsdOx1ZoWYgkSU5juLE1f/rc5Hlp7GF2dna4d+8ev//+O7u7u2xvb1OtVv+5Qur1OqVSiXK57CTS5vl/Ehp9lHQ6zfr6Op9//jnffvstpVIJ0zQpFovOfqcTtCzEtm3nKKBSqTi70uelkXs2NzdJJpPcuXOHX375pdUwn5m2CLEsi9XVVT788ENefvllrl69itvtPjJJHkYjr9y+fZubN2/y22+/sba2xsbGRqshnoi2CKlUKmxvb6PrOrZtMzc3h8/nc85d/+rwqDHKDMMgmUzyxRdfsLOzQ6FQaDW8E9OyEF3XWVpack7lG8lvYGCAmZkZYrEY4+PjiKJ46FRqjIz79+/z448/8sMPP5DJZNpypPA8tCzEsqx9FWO9Xsfr9RKPx52OV39/v/MIVHNPtVwuo+s6jx49Ynl5mfX19Y4lzGeh7Q/diaLonMIFg0EUReHMmTPHjpBqtep0vhqn/Z3mqIfuTv0pxH8K3f+XeUa6QproCmmiK6SJrpAmukKaOHbZ/X+kO0Ka6Appoiukia6QJrpCmugKaeI/KZ4b0jktDIQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image(tensor(Image.open(threes_train_f.ls()[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5b308f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all images\n",
    "threes_train = torch.stack([tensor(Image.open(x)) for x in threes_train_f.ls().sorted()]).float()/255\n",
    "seven_train = torch.stack([tensor(Image.open(x)) for x in seven_train_f.ls().sorted()]).float()/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5ecc9859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all validation images\n",
    "threes_valid = torch.stack([tensor(Image.open(x)) for x in threes_valid_f.ls()]).float()/255\n",
    "seven_valid = torch.stack([tensor(Image.open(x)) for x in seven_valid_f.ls()]).float()/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c78f42fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6131, 28, 28]), <AxesSubplot:>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "threes_train.shape, show_image(threes_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0b2d7180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<AxesSubplot:>, <AxesSubplot:>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "threes_mean = threes_train.mean(0)\n",
    "sevens_mean = seven_train.mean(0)\n",
    "show_image(threes_mean), show_image(sevens_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "710963d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1 dist. sevens = 0.1715536266565323, threes = 0.10742203146219254\n",
      "l2 dist. sevens = 0.30306190252304077, threes = 0.19120194017887115\n"
     ]
    }
   ],
   "source": [
    "def l1_dist(t): return (t - threes_mean).abs().mean()\n",
    "print( f'l1 dist. sevens = {l1_dist(seven_train[0])}, threes = {l1_dist(threes_train[0])}')\n",
    "\n",
    "def l2_dist(t): return (t - threes_mean).square().mean().sqrt()\n",
    "print( f'l2 dist. sevens = {l2_dist(seven_train[0])}, threes = {l2_dist(threes_train[0])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ade94cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_loss(t, mean): return (t - mean).square().mean((-2,-1)).sqrt()\n",
    "\n",
    "def is_3(t): return rmse_loss(t, threes_mean) < rmse_loss(t, sevens_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1de8aec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([12396, 28, 28]), torch.Size([12396]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_xs = torch.cat( (threes_train, seven_train) )\n",
    "train_preds = is_3(train_xs)\n",
    "train_xs.shape, train_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d1c11e11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ True,  True,  True,  ..., False, False, False]), torch.Size([12396]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_ys(shape, bool_val): return tensor(bool_val).expand(shape)\n",
    "\n",
    "train_ys = torch.cat( [get_ys(threes_train.shape[0], True), get_ys(seven_train.shape[0], False)])\n",
    "train_ys, train_ys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "13301f4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def accuracy(preds, labels):\n",
    "    correct = (preds>0.5) == labels\n",
    "    return correct.float().mean()\n",
    "\n",
    "accuracy(tensor(0.7), tensor(False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0ccb0049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2038, 1]), tensor(0.1919))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_xs = torch.cat([threes_valid, seven_valid])\n",
    "valid_preds = is_3(valid_xs)\n",
    "\n",
    "valid_ys = torch.cat( [get_ys(threes_valid.shape[0], True), get_ys(seven_valid.shape[0], False)]).unsqueeze(1)\n",
    "\n",
    "valid_ys.shape, valid_xs[0].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac7c2b9",
   "metadata": {},
   "source": [
    "## SGD\n",
    "\n",
    "Stochastic gradient descent\n",
    "\n",
    "We're trying to predict `3` or `7`. We can imagine a prediction function that will give a score. We can say that `3` is `1.0` and `7` is `0.` to reframe the binary classification problem. Thus, if the prediction is greater than 0.5, it's a `3` otherwise it's a `7`. Based on the distance, we assign a loss.\n",
    "\n",
    "We guess function of the form: `y = ax + b`.\n",
    "\n",
    "Need to find the right `a` and `b`. Calc gradient to change `a`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6ebee9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(actuals, preds):\n",
    "    return (preds.float() - actuals.float()).abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a3e0cc6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4256)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mnist_loss(predictions, targets):\n",
    "    predictions = predictions.sigmoid()\n",
    "    return torch.where(targets==1, 1-predictions, predictions).mean()\n",
    "\n",
    "mnist_loss(tensor(0.3), tensor(1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "997a3dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(size, seed=None, std=1.0):\n",
    "    if seed is not None:\n",
    "        torch.manual_seed(seed)\n",
    "    else:\n",
    "        torch.seed()\n",
    "    return (torch.randn(size)*std).requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7483e66f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12396, 784])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_xs = train_xs.reshape((-1, 28 * 28))\n",
    "train_xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "586b0a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_xs = valid_xs.view((-1, 28 * 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ea903c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear1(weights, bias, inputs):\n",
    "    return torch.sigmoid(inputs@weights + bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "95f64217",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(preds, labels):\n",
    "    correct = (preds>0.5) == labels\n",
    "    return correct.float().mean()\n",
    "\n",
    "def model_accuracy(model, xs, ys):\n",
    "    preds = model(xs)\n",
    "    return accuracy(preds, ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ebb477",
   "metadata": {},
   "source": [
    "Matrix multiplication of weights and inputs (12396, 28 * 28). Shape of 'y' is 12396.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "707a3031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train 1 epoch\n",
    "\n",
    "def train_epoch(dl, weights, bias, lr):\n",
    "    for inputs,labels in dl:\n",
    "        preds = linear1(weights, bias, inputs)\n",
    "        l = mnist_loss(preds.float(), labels.float())\n",
    "    #     print(f'loss = {l}')\n",
    "        l.backward()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            weights.data -= weights.grad * lr\n",
    "            bias.data -= bias.grad * lr\n",
    "    #         print(f'weights_init == weights, bias_init == bias = {torch.equal(weights_init, weights), torch.equal(bias_init, bias)}')\n",
    "\n",
    "            weights.grad.zero_()\n",
    "            bias.grad.zero_()\n",
    "\n",
    "    return weights, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0c086f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1472), tensor(1.))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_dl(xs, ys):\n",
    "    torch.manual_seed(42)\n",
    "    return DataLoader(list(zip(xs, ys)), batch_size=256)\n",
    "\n",
    "dl = create_dl(train_xs, train_ys)\n",
    "f = first(dl)\n",
    "f[0].mean(), f[1].float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae0f27c",
   "metadata": {},
   "source": [
    "#### Training ONE Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "12e03f20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1472), tensor(0.6658))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = init_params((28 * 28, 1), seed=42)\n",
    "bias = init_params(1, seed=42)\n",
    "\n",
    "dl = create_dl(train_xs, train_ys)\n",
    "lr = 1.\n",
    "train_epoch(dl, weights, bias, lr)\n",
    "first(dl)[0].mean(), model_accuracy(partial(linear1, weights, bias), valid_xs, valid_ys)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7faa30c7",
   "metadata": {},
   "source": [
    "#### Training Multiple Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b8f218d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_accuracy(weights, bias):\n",
    "    train_accuracy = accuracy(linear1(weights, bias, train_xs), train_ys)\n",
    "    valid_accuracy = accuracy(linear1(weights, bias, valid_xs), valid_ys)\n",
    "    print(f'train accuracy = {train_accuracy}, valid accuracy = {valid_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d53e63dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epochs(lr, inputs, labels):\n",
    "    \n",
    "    dl = DataLoader(list(zip(inputs, labels)), batch_size=256)\n",
    "    \n",
    "    weights = init_params((28 * 28, 1), seed=42)\n",
    "    bias = init_params(1, seed=42)\n",
    "    \n",
    "    print_accuracy(weights, bias)\n",
    "\n",
    "    for _ in range(21):\n",
    "        train_epoch(dl, weights, bias, lr)\n",
    "        print_accuracy(weights, bias)\n",
    "    \n",
    "    return (weights, bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a0b1ac0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy = 0.5040044784545898, valid accuracy = 0.5456329584121704\n",
      "train accuracy = 0.5028986930847168, valid accuracy = 0.6658488512039185\n",
      "train accuracy = 0.5017519593238831, valid accuracy = 0.7801766395568848\n",
      "train accuracy = 0.5010551810264587, valid accuracy = 0.8434739708900452\n",
      "train accuracy = 0.5006967782974243, valid accuracy = 0.8709518909454346\n",
      "train accuracy = 0.500484049320221, valid accuracy = 0.8900883197784424\n",
      "train accuracy = 0.5003548860549927, valid accuracy = 0.9072620272636414\n",
      "train accuracy = 0.5002772808074951, valid accuracy = 0.9195289611816406\n",
      "train accuracy = 0.500240683555603, valid accuracy = 0.9278704524040222\n",
      "train accuracy = 0.500217080116272, valid accuracy = 0.9317958950996399\n",
      "train accuracy = 0.5002110004425049, valid accuracy = 0.9367026686668396\n",
      "train accuracy = 0.5002232193946838, valid accuracy = 0.9411187171936035\n",
      "train accuracy = 0.5002023577690125, valid accuracy = 0.9425907731056213\n",
      "train accuracy = 0.5001927018165588, valid accuracy = 0.9460254907608032\n",
      "train accuracy = 0.500188410282135, valid accuracy = 0.9479882121086121\n",
      "train accuracy = 0.5001822113990784, valid accuracy = 0.9479882121086121\n",
      "train accuracy = 0.5001831650733948, valid accuracy = 0.9484788775444031\n",
      "train accuracy = 0.5001857876777649, valid accuracy = 0.9499509334564209\n",
      "train accuracy = 0.5001866221427917, valid accuracy = 0.9504415988922119\n",
      "train accuracy = 0.5001840591430664, valid accuracy = 0.9509322643280029\n",
      "train accuracy = 0.5001823306083679, valid accuracy = 0.9528949856758118\n",
      "train accuracy = 0.50018310546875, valid accuracy = 0.9538763761520386\n"
     ]
    }
   ],
   "source": [
    "final_weights, final_bias = train_epochs(1., train_xs, train_ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0abb9e",
   "metadata": {},
   "source": [
    "#### Adding a Learner and using pytorch idioms to simplify what we did manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0505d2ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 784]), torch.Size([4]))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w,b = nn.Linear(28*28, 4).parameters()\n",
    "w.shape, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f5370d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = create_dl(train_xs, train_ys)\n",
    "valid_dl = create_dl(valid_xs, valid_ys)\n",
    "dls = DataLoaders(train_dl, valid_dl)\n",
    "\n",
    "model = nn.Linear(28*28, 1)\n",
    "\n",
    "learner = Learner(dls, model, loss_func=mnist_loss, opt_func=SGD, lr=1., metrics=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f223e185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.637268</td>\n",
       "      <td>0.501795</td>\n",
       "      <td>0.495584</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.313231</td>\n",
       "      <td>0.324950</td>\n",
       "      <td>0.608930</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.125592</td>\n",
       "      <td>0.160476</td>\n",
       "      <td>0.830716</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.061204</td>\n",
       "      <td>0.099966</td>\n",
       "      <td>0.900393</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.037092</td>\n",
       "      <td>0.074423</td>\n",
       "      <td>0.927380</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.027350</td>\n",
       "      <td>0.060362</td>\n",
       "      <td>0.941119</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.023108</td>\n",
       "      <td>0.051517</td>\n",
       "      <td>0.951914</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.021052</td>\n",
       "      <td>0.045555</td>\n",
       "      <td>0.956330</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.019898</td>\n",
       "      <td>0.041314</td>\n",
       "      <td>0.960255</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.019140</td>\n",
       "      <td>0.038159</td>\n",
       "      <td>0.965653</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.018574</td>\n",
       "      <td>0.035723</td>\n",
       "      <td>0.966634</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.018114</td>\n",
       "      <td>0.033778</td>\n",
       "      <td>0.968106</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.017725</td>\n",
       "      <td>0.032181</td>\n",
       "      <td>0.969578</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.017391</td>\n",
       "      <td>0.030842</td>\n",
       "      <td>0.970069</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.017104</td>\n",
       "      <td>0.029704</td>\n",
       "      <td>0.973503</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.016855</td>\n",
       "      <td>0.028725</td>\n",
       "      <td>0.973503</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.016637</td>\n",
       "      <td>0.027876</td>\n",
       "      <td>0.973994</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.016445</td>\n",
       "      <td>0.027135</td>\n",
       "      <td>0.975466</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.016272</td>\n",
       "      <td>0.026482</td>\n",
       "      <td>0.976938</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.016116</td>\n",
       "      <td>0.025904</td>\n",
       "      <td>0.976938</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.015972</td>\n",
       "      <td>0.025389</td>\n",
       "      <td>0.976938</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.fit(n_epoch=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc617575",
   "metadata": {},
   "source": [
    "#### Adding Non-linearity and neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1a2e98ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(28 * 28, 30), nn.ReLU(), nn.Linear(30,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "57849198",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = Learner(dls, model, loss_func=mnist_loss, opt_func=SGD, lr=1., metrics=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a594446a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.181939</td>\n",
       "      <td>0.491330</td>\n",
       "      <td>0.504416</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.095837</td>\n",
       "      <td>0.218973</td>\n",
       "      <td>0.766928</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.046969</td>\n",
       "      <td>0.115624</td>\n",
       "      <td>0.882237</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.029303</td>\n",
       "      <td>0.078532</td>\n",
       "      <td>0.920510</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.062345</td>\n",
       "      <td>0.933268</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.018141</td>\n",
       "      <td>0.052594</td>\n",
       "      <td>0.944553</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.016190</td>\n",
       "      <td>0.046608</td>\n",
       "      <td>0.953386</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.014877</td>\n",
       "      <td>0.042937</td>\n",
       "      <td>0.954858</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.013932</td>\n",
       "      <td>0.040417</td>\n",
       "      <td>0.959274</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.013198</td>\n",
       "      <td>0.038484</td>\n",
       "      <td>0.961236</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.012551</td>\n",
       "      <td>0.036844</td>\n",
       "      <td>0.961727</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.011992</td>\n",
       "      <td>0.035349</td>\n",
       "      <td>0.963199</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.011577</td>\n",
       "      <td>0.033903</td>\n",
       "      <td>0.963690</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.011292</td>\n",
       "      <td>0.032534</td>\n",
       "      <td>0.965653</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.011088</td>\n",
       "      <td>0.031293</td>\n",
       "      <td>0.967615</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.010919</td>\n",
       "      <td>0.030130</td>\n",
       "      <td>0.968597</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.010753</td>\n",
       "      <td>0.029011</td>\n",
       "      <td>0.970069</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.010574</td>\n",
       "      <td>0.027965</td>\n",
       "      <td>0.970559</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.010385</td>\n",
       "      <td>0.027052</td>\n",
       "      <td>0.973994</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.010196</td>\n",
       "      <td>0.026305</td>\n",
       "      <td>0.974485</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.010019</td>\n",
       "      <td>0.025717</td>\n",
       "      <td>0.975466</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.fit(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4276d2ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.092521</td>\n",
       "      <td>0.012846</td>\n",
       "      <td>0.995584</td>\n",
       "      <td>00:22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls = ImageDataLoaders.from_folder(path)\n",
    "learn = cnn_learner(dls, resnet18, pretrained=False,\n",
    "                    loss_func=F.cross_entropy, metrics=fastai.metrics.accuracy)\n",
    "learn.fit_one_cycle(1, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "500b3df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc(cnn_learner)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812a5b48",
   "metadata": {},
   "source": [
    "1. How is a grayscale image represented on a computer? How about a color image?\n",
    "    \n",
    "    Matrix with an element for each pixel and the value of that pixel is represents how light or dark that pixel is. For a colour image, it could be done the same way with each pixel value being the hex value of the colour that it represents.\n",
    "\n",
    "\n",
    "2. How are the files and folders in the `MNIST_SAMPLE` dataset structured? Why?\n",
    "\n",
    "   Separated by the digits and within each digit, there's a folder for training and another for validation. This makes it easy to do training and validation on each digit.\n",
    "\n",
    "\n",
    "3. Explain how the \"pixel similarity\" approach to classifying digits works.\n",
    "\n",
    "    Take the mean value of each pixel in the training set so that you can come up with a mean 3, a mean 7, etc. Then for any image, check the mean distance of the image from the mean 3 and mean 7 (mean 8, etc. if you're classifying those as well) to see if the image is closer to a `3` or a `7` and then classify it that way.\n",
    "\n",
    "\n",
    "4. What is a list comprehension? Create one now that selects odd numbers from a list and doubles them.\n",
    "\n",
    "   List comprehension in python is building a list from an iterable through a short-hand syntax as opposed to writing a for loop and pushing elements to the list in that fashion.\n",
    "\n",
    "\n",
    "5. What is a \"rank-3 tensor\"?\n",
    "\n",
    "    3 dim tensor\n",
    "\n",
    "\n",
    "6. What is the difference between tensor rank and shape? How do you get the rank from the shape?\n",
    "\n",
    "    Rank is number of dimensions. Shape is length of each dimension and therefore also tells the rank.\n",
    "\n",
    "\n",
    "7. What are RMSE and L1 norm?\n",
    "\n",
    "    Root Mean Square error is the mean ( sqrt( sum of squares of individual distances) ). l1 = mean ( sum of absolute value of individual distances )\n",
    "\n",
    "\n",
    "8. How can you apply a calculation on thousands of numbers at once, many thousands of times faster than a Python loop?\n",
    "\n",
    "    By doing an operation on a an entire tensor such as tensor * 2. pytorch has optimized code that will run this on a gpu.\n",
    "\n",
    "\n",
    "9. Create a 3Ã—3 tensor or array containing the numbers from 1 to 9. Double it. Select the bottom-right four numbers.\n",
    "\n",
    "    \n",
    "\n",
    "10. What is broadcasting?\n",
    "\n",
    "    Amending the shape of a tensor of lower rank  to a higher rank and/or dimension, in order to make it compatible for an operation with another tensor is broadcasting.\n",
    "\n",
    "\n",
    "11. Are metrics generally calculated using the training set, or the validation set? Why?\n",
    "\n",
    "    metrics are generally calculated using the validation set because if you just look at training set, you don't know if you're actually doing well or overfitting.\n",
    "\n",
    "\n",
    "12. What is SGD?\n",
    "\n",
    "    Stochastic gradient descent.\n",
    "\n",
    "\n",
    "13. Why does SGD use mini-batches?\n",
    "\n",
    "    Inefficient to train on entire training set each time.\n",
    "\n",
    "\n",
    "14. What are the seven steps in SGD for machine learning?\n",
    "\n",
    "    - Create DataLoader to separate data between training and validation.\n",
    "    - Pick a metric to see how well the algorithm is doing\n",
    "    - Randomly initialize `weights` and `bias`\n",
    "    - Define a loss function in order to update the parameters.\n",
    "    - Pick a small subset of the training data (mini-batch)\n",
    "    - For each data point, evaluate the gradient of the loss function wrt the parameters at the point.\n",
    "    - Update the parameters suitably (multiplying gradient by learning rate)\n",
    "    - Pick a new batch and repeat until desired.\n",
    "\n",
    "\n",
    "15. How do we initialize the weights in a model?\n",
    "\n",
    "    Randomly\n",
    "\n",
    "\n",
    "16. What is \"loss\"?\n",
    "\n",
    "    \"loss\" is a function that can be used to tell the algorithm how well the parameters are doing. In addition, it should be a suitable function such that it has gradients everywhere so that the parameters can be updated.\n",
    "\n",
    "\n",
    "17. Why can't we always use a high learning rate?\n",
    "\n",
    "    With a high learning rate, we might not reach a local minima and instead keeping bouncing around it while doing SGD.\n",
    "    \n",
    "\n",
    "18. What is a \"gradient\"?\n",
    "\n",
    "    Rise over run or slope of a function at a point.\n",
    "\n",
    "\n",
    "19. Do you need to know how to calculate gradients yourself?\n",
    "\n",
    "    No\n",
    "\n",
    "\n",
    "20. Why can't we use accuracy as a loss function?\n",
    "\n",
    "    loss function needs to have smooth gradients everywhere in order for the algorithm to be able to properly update the parameters.\n",
    "\n",
    "\n",
    "21. Draw the sigmoid function. What is special about its shape?\n",
    "\n",
    "   It's an S-shape so that it has gradients defined everywhere.\n",
    "\n",
    "\n",
    "22. What is the difference between a loss function and a metric?\n",
    "\n",
    "    loss function is for the algorithm to automatically update parameters. metric is for a human to determine how well the algorithm is doing\n",
    "\n",
    "\n",
    "23. What is the function to calculate new weights using a learning rate?\n",
    "\n",
    "    gradient * learning rate\n",
    "\n",
    "\n",
    "24. What does the `DataLoader` class do?\n",
    "\n",
    "    Separates data into training and validation and breaks it into mini-batches such that SGD can be performed.\n",
    "\n",
    "\n",
    "25. Write pseudocode showing the basic steps taken in each epoch for SGD.\n",
    "\n",
    "    for x,y in data loader:\n",
    "        y_p = f(x)\n",
    "        loss = loss_f(y, y_p)\n",
    "        loss.backward()\n",
    "        weights = weights - weights.grad * lr\n",
    "        \n",
    "    accuracy = accuracy_func( f(x_validation, new_weights), y_validation )\n",
    "\n",
    "\n",
    "26. Create a function that, if passed two arguments `[1,2,3,4]` and `'abcd'`, returns `[(1, 'a'), (2, 'b'), (3, 'c'), (4, 'd')]`. What is special about that output data structure?\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "27. What does `view` do in PyTorch?\n",
    "\n",
    "    reshapes\n",
    "\n",
    "\n",
    "28. What are the \"bias\" parameters in a neural network? Why do we need them?\n",
    "\n",
    "\n",
    "\n",
    "29. What does the `@` operator do in Python?\n",
    "\n",
    "    tensor Multiplication\n",
    "\n",
    "\n",
    "30. What does the `backward` method do?\n",
    "\n",
    "    gradient calc\n",
    "\n",
    "\n",
    "31. Why do we have to zero the gradients?\n",
    "\n",
    "    pytorch adds the gradient values to existing stored gradient val of the tensor.\n",
    "\n",
    "\n",
    "32. What information do we have to pass to `Learner`?\n",
    "\n",
    "    dataloaders, loss func, accuracy func, num epochs, learning rate\n",
    "\n",
    "\n",
    "33. Show Python or pseudocode for the basic steps of a training loop.\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "34. What is \"ReLU\"? Draw a plot of it for values from `-2` to `+2`.\n",
    "\n",
    "    max(0, x)\n",
    "\n",
    "\n",
    "35. What is an \"activation function\"?\n",
    "\n",
    "    layer function\n",
    "\n",
    "\n",
    "36. What's the difference between `F.relu` and `nn.ReLU`?\n",
    "\n",
    "    `F.relu` is a function where as `nn.ReLU` is a class\n",
    "\n",
    "\n",
    "37. The universal approximation theorem shows that any function can be approximated as closely as needed using just one nonlinearity. So why do we normally use more?\n",
    "\n",
    "    Deeper layers means fewer overall paramters which indirectly (but not sure how) means we need less memory to train the model and it can be trained faster.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e65b507d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 14]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 4. List comprehension question\n",
    "\n",
    "def create_odd_double(iterable):\n",
    "    return [ x * 2 for x in iterable if x % 2 == 1]\n",
    "\n",
    "create_odd_double([2, 4, 3, 7, 10, 12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d119f48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10, 12],\n",
       "        [16, 18]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 9. Create a 3Ã—3 tensor or array containing the numbers from 1 to 9. Double it. Select the bottom-right four numbers.\n",
    "\n",
    "t = torch.tensor( [ [1, 2, 3], [4, 5, 6], [7, 8, 9] ] )\n",
    "t = t * 2\n",
    "t[1:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "122db760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 'a'), (3, 'b'), (4, 'c'), (5, 'd')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 26.\n",
    "\n",
    "def tuplize(a, b):\n",
    "    return [(x,y) for x,y in zip(a,b)]\n",
    "\n",
    "tuplize([2,3, 4, 5], 'abcd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "48fc7024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  2,   3,   5],\n",
       "         [325,  25,  67]]),\n",
       " torch.Size([2, 3]),\n",
       " tensor([[  2,   3,   5],\n",
       "         [325,  25,  67]]),\n",
       " torch.Size([2, 3]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tensor([2, 3, 5], [325, 25, 67])\n",
    "t1 = tensor([ [2, 3, 5], [325, 25, 67] ])\n",
    "t, t.shape, t1, t1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fc7b2d8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 16.],\n",
       "        [198.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(x, w):\n",
    "    return x @ (w ** 2)\n",
    "\n",
    "w = tensor([4], [33]).float().requires_grad_()\n",
    "y = f(tensor([2, 3]).float(), w)\n",
    "y.backward()\n",
    "w.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2ca44de8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 32.],\n",
       "        [396.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = f(tensor([2, 3]).float(), w)\n",
    "y.backward()\n",
    "w.grad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
